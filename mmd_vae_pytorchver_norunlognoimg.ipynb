{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dim = 3\n",
    "usecuda = True\n",
    "idgpu = 2\n",
    "epochs = 40\n",
    "kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=200, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False,download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=200, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder and decoder use the DC-GAN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChannelsToLinear(nn.Linear):\n",
    "    \"\"\"Flatten a Variable to 2d and apply Linear layer\"\"\"\n",
    "    def forward(self, x):\n",
    "        b = x.size(0)\n",
    "        return super().forward(x.view(b,-1))\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        n_filters = 64\n",
    "        self.conv1 = nn.Conv2d(1, n_filters, 4,2,1)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters*2, 4, 2,1)\n",
    "        \n",
    "        self.toLinear1 =  ChannelsToLinear(n_filters*2*7*7, 1024)\n",
    "        self.fc1 = nn.Linear(1024,z_dim)\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h1 = self.lrelu(self.conv1(x))\n",
    "        h2 = self.lrelu(self.conv2(h1))\n",
    "        h3 = self.lrelu(self.toLinear1(h2))\n",
    "        h4 = self.fc1(h3)\n",
    "        \n",
    "        return h4\n",
    "        \n",
    "encodermodel = Encoder()\n",
    "if usecuda:\n",
    "    encodermodel.cuda(idgpu)       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearToChannels2d(nn.Linear):\n",
    "    \"\"\"Reshape 2d Variable to 4d after Linear layer\"\"\"\n",
    "    def __init__(self, m, n, w=1, h=None, **kw):\n",
    "        h = h or w\n",
    "        super().__init__(m, n*w*h, **kw)\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "    def forward(self, x):\n",
    "        b = x.size(0)\n",
    "        return super().forward(x).view(b, -1, self.w, self.h)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        n_filters = 64\n",
    "        \n",
    "        self.fc1 = nn.Linear(z_dim,1024)\n",
    "        self.LineartoChannel = LinearToChannels2d(1024,n_filters*2,7,7)\n",
    "        self.conv1 = nn.ConvTranspose2d(n_filters*2,n_filters,4,2,1)\n",
    "        self.conv2 = nn.ConvTranspose2d(n_filters,1,4,2,1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,z):\n",
    "        h1 = self.relu(self.fc1(z))\n",
    "        h2 = self.relu(self.LineartoChannel(h1))\n",
    "        \n",
    "        h3 = self.relu(self.conv1(h2))\n",
    "        h4 = self.sigmoid(self.conv2(h3))\n",
    "        \n",
    "        return h4\n",
    "        \n",
    "decodermodel = Decoder()\n",
    "if usecuda:\n",
    "    decodermodel.cuda(idgpu)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_kernel(x, y):\n",
    "    x_size = x.shape[0]\n",
    "    y_size = y.shape[0]\n",
    "    dim = x.shape[1]\n",
    "\n",
    "    tiled_x = x.view(x_size,1,dim).repeat(1, y_size,1)\n",
    "    tiled_y = y.view(1,y_size,dim).repeat(x_size, 1,1)\n",
    "\n",
    "    return torch.exp(-torch.mean((tiled_x - tiled_y)**2,dim=2)/dim*1.0)\n",
    "\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    return torch.mean(x_kernel) + torch.mean(y_kernel) - 2*torch.mean(xy_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert a numpy array of shape [batch_size, height, width, 1] into a displayable array \n",
    "# of shape [height*sqrt(batch_size, width*sqrt(batch_size))] by tiling the images\n",
    "def convert_to_display(samples):\n",
    "    cnt, height, width = int(math.floor(math.sqrt(samples.shape[0]))), samples.shape[1], samples.shape[2]\n",
    "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
    "    samples = np.reshape(samples, [height, cnt, cnt, width])\n",
    "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
    "    samples = np.reshape(samples, [height*cnt, width*cnt])\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seaborn-talk',\n",
       " 'grayscale',\n",
       " 'classic',\n",
       " 'Solarize_Light2',\n",
       " 'seaborn',\n",
       " 'seaborn-colorblind',\n",
       " 'ggplot',\n",
       " 'fivethirtyeight',\n",
       " 'seaborn-bright',\n",
       " 'seaborn-ticks',\n",
       " 'seaborn-pastel',\n",
       " 'seaborn-dark',\n",
       " 'seaborn-dark-palette',\n",
       " 'seaborn-darkgrid',\n",
       " 'bmh',\n",
       " 'seaborn-white',\n",
       " 'seaborn-paper',\n",
       " 'fast',\n",
       " 'tableau-colorblind10',\n",
       " 'seaborn-poster',\n",
       " 'dark_background',\n",
       " 'seaborn-whitegrid',\n",
       " 'seaborn-deep',\n",
       " '_classic_test',\n",
       " 'seaborn-notebook',\n",
       " 'seaborn-muted']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot before training the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If latent z is 2-dimensional we visualize it by plotting latent z of different digits in different colors\n",
    "if z_dim == 3:\n",
    "    z_list, label_list = [], []\n",
    "    test_batch_size = 500\n",
    "    #for i in range(20):\n",
    "    i = 1\n",
    "    for batch_idx, (test_x, test_y) in enumerate(test_loader):\n",
    "        if(i>20):\n",
    "            break\n",
    "        test_x= Variable(test_x)\n",
    "        if(usecuda):\n",
    "            test_x = test_x.cuda(idgpu)\n",
    "        z = encodermodel(test_x)   \n",
    "        z_list.append(z.data.cpu())\n",
    "        label_list.append(test_y)\n",
    "        i = i+1\n",
    "    z = np.concatenate(z_list, axis=0)\n",
    "    label = np.concatenate(label_list)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "#     plt.style.use('_classic_test')\n",
    "    ax.scatter(z[:, 0], z[:, 1],z[:, 2], c=label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizerencoder = optim.Adam(encodermodel.parameters(), lr=1e-3)\n",
    "optimizerdecoder = optim.Adam(decodermodel.parameters(), lr=1e-3)\n",
    "for i in range(epochs):\n",
    "\n",
    "    for batch_idx, (train_x, _) in enumerate(train_loader): \n",
    "        train_x= Variable(train_x)\n",
    "           \n",
    "        true_samples = torch.randn((len(train_x),z_dim))\n",
    "        true_samples = Variable(true_samples)\n",
    "        \n",
    "        if(usecuda):\n",
    "            train_x = train_x.cuda(idgpu)\n",
    "            true_samples = true_samples.cuda(idgpu)\n",
    "        \n",
    "        optimizerencoder.zero_grad()\n",
    "        optimizerdecoder.zero_grad()\n",
    "        \n",
    "        train_z = encodermodel(train_x)\n",
    "        \n",
    "        train_xr = decodermodel(train_z)\n",
    "        \n",
    "        loss_mmd = compute_mmd(true_samples, train_z)\n",
    "        loss_nll = torch.mean((train_xr - train_x)**2)\n",
    "        \n",
    "        loss = loss_nll + loss_mmd\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizerencoder.step()\n",
    "        optimizerdecoder.step()\n",
    "        \n",
    "        if(batch_idx%100 == 0):\n",
    "            print(\"Epoch %d : Negative log likelihood is %f, mmd loss is %f\" % (i,loss_nll.data[0], loss_mmd.data[0]))\n",
    "            \n",
    "        \n",
    "    # show images\n",
    "    gen_z = Variable(torch.randn((100, z_dim)))\n",
    "    if(usecuda):\n",
    "        gen_z = gen_z.cuda(idgpu)\n",
    "    samples = decodermodel(gen_z)\n",
    "    samples =samples.view(100,28,28,1)\n",
    "    plt.imshow(convert_to_display(samples.data), cmap='Greys_r')\n",
    "    plt.show()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot after training the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If latent z is 2-dimensional we visualize it by plotting latent z of different digits in different colors\n",
    "if z_dim == 3:\n",
    "    z_list, label_list = [], []\n",
    "    test_batch_size = 500\n",
    "    #for i in range(20):\n",
    "    i = 1\n",
    "    for batch_idx, (test_x, test_y) in enumerate(test_loader):\n",
    "        if(i>20):\n",
    "            break\n",
    "        test_x= Variable(test_x)\n",
    "        if(usecuda):\n",
    "            test_x = test_x.cuda(idgpu)\n",
    "        z = encodermodel(test_x)   \n",
    "        z_list.append(z.data.cpu())\n",
    "        label_list.append(test_y)\n",
    "        i = i+1\n",
    "    z = np.concatenate(z_list, axis=0)\n",
    "    label = np.concatenate(label_list)\n",
    "#     plt.scatter(z[:, 0], z[:, 1], c=label)\n",
    "#     plt.show()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "#     plt.style.use('_classic_test')\n",
    "    ax.scatter(z[:, 0], z[:, 1],z[:, 2], c=label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
